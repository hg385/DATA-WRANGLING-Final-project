---
html_document: default
author: "Hao Guo Wentao Lu JiaoZhe Zhang"
date: "05/06/2022"
title: "NYC Taxi"
---

Using the tidyverse because it has the libraries to clean, mutate and visualize data. library(data.table) - helps load data faster then read csv

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(lubridate)
library(magrittr)
library(flexdashboard)
library(ggrepel)
library(formattable)
library(sf)
library(plotly)
library(treemapify)
library(scales)
library(RColorBrewer)
library(formatR)
library(caret)
library(rgdal)
```

Loading all of the excel files into Rstudio

```{r}
taxi_data_2017 <- fread("2017_taxi_trips.csv")
taxi_data_2018 <- fread("2018_taxi_trips.csv")
```

```{r}
taxi_data_2019 <- fread("2019_taxi_trips.csv")
taxi_data_2020 <- fread("2020_taxi_trips.csv")
```

Noticed taxi_data_2019 & 2020 have 19 columns checked the first 6 rows to see what it is.

```{r}
head(taxi_data_2019)
```

```{r}
head(taxi_data_2020)
```

At first I tried to union_all the 4 dataframes which took too long which resulted in the total rows being 8M less. I decided to conduct two separate union_all statements to fix the issue.

```{r}
taxi_data_all <- union_all(taxi_data_2017, taxi_data_2018)
```

```{r}
taxi_data_all_2 <- union_all(taxi_data_2019, taxi_data_2020)
```

```{r}
taxi_data_all_final <- union_all(taxi_data_all, taxi_data_all_2)
```

Garbage collection function to print memory usage statistics as previously I was receiving this error.

```{r}
gc()
```

Removed previous dataframes to save GB in Global Environment

```{r}
remove(taxi_data_2017, taxi_data_2018, taxi_data_2019, taxi_data_2020, taxi_data_all, taxi_data_all_2)
```

View data types

```{r}
glimpse(taxi_data_all_final)
```

**Cleaning requirements:**

1.  Remove trips that were NOT sent via "store and forward".

```{r}
taxi_data_clean <- taxi_data_all_final %>% 
  filter(store_and_fwd_flag == "N")
```

```{r}
remove(taxi_data_all_final)
```

2.  Only keep street-hailed trips paid by card or cash with a standard rate.

```{r}
taxi_data_clean <- taxi_data_clean  %>% 
  filter(RatecodeID == 1 & (payment_type < 3))
#RateCodeID & payment_type are both int
```

```{r}
head(taxi_data_clean)
```

3.  Remove any trips before 2017 or after 2020, along with any trips or pickups or drop-offs into unknown zones.

```{r}
taxi_data_clean <- taxi_data_clean  %>% 
  filter(between (lpep_pickup_datetime, as.Date("2017-01-01"), as.Date ("2021-01-01")))
```

4.  Any trips with no recorded passengers had 1 passenger.

```{r}
taxi_data_clean <- taxi_data_clean  %>% 
mutate(passenger_count = if_else(passenger_count == 0, 1, 1)) 
```

Verify it worked

```{r}
min(taxi_data_clean$passenger_count)
```

5.  If pickup date/time is AFTER drop-off date/time, swap them.

```{r}
taxi_data_clean <- taxi_data_clean  %>% 
mutate(lpep_pickup_datetime = if_else(lpep_dropoff_datetime < lpep_pickup_datetime, lpep_dropoff_datetime, lpep_pickup_datetime))
```

Cleaning step worked

```{r}
taxi_data_clean %>% 
filter(lpep_dropoff_datetime < lpep_pickup_datetime)
```

6.  Remove any trips lasting longer than a day, and any trips which show a distance and fare amount of zero.

```{r}
taxi_data_clean <- taxi_data_clean %>% 
  mutate(trip_hours = difftime(taxi_data_clean$lpep_dropoff_datetime, taxi_data_clean$lpep_pickup_datetime, units = "hours"))
```

Verifying the time difference

```{r}
max(taxi_data_clean$trip_hours)
```

```{r}
taxi_data_clean <- taxi_data_clean  %>% 
  filter(trip_hours <= 24) %>% 
  filter(trip_distance > 0 & (fare_amount > 0))
```

Verifying that anything greater then a day and removed anything that was 0.

```{r}
max(taxi_data_clean$trip_hours)
min(taxi_data_clean$trip_distance)
min(taxi_data_clean$fare_amount)
```

7.  If any fare, taxed and surcharge are negative make positive.

```{r}
min(taxi_data_clean$fare_amount)
min(taxi_data_clean$mta_tax)
min(taxi_data_clean$congestion_surcharge)
summary(taxi_data_clean$congestion_surcharge)
```

Removing columns that are not required for analysis

```{r}
taxi_data_clean$VendorID <- NULL
taxi_data_clean$RatecodeID <- NULL
```

Another way to remove a column by name

```{r}
select(taxi_data_clean, -extra, -mta_tax, -tolls_amount)
```

Importing the next dataframe

```{r}
taxi_zones <- fread("taxi_zones.csv")
```

Viewing the new dataframe

```{r}
head(taxi_zones)
```

Joining the new dataframe by pickup location ID

```{r}
taxi_data_join <- taxi_data_clean  %>% 
  inner_join(taxi_zones, by = c("PULocationID" = "LocationID"))
#View(taxi_data_join)#
```

Joining the new dataframe by dropoff location ID

```{r}
taxi_data_join <- taxi_data_join  %>% 
  inner_join(taxi_zones, by = c("DOLocationID" = "LocationID"))
```

Renaming columns

```{r}
taxi_data_join <- taxi_data_join %>% 
  #select(Borough.x, Zone.x, service_zone.x, Borough.y, Zone.y, service_zone.y) %>% 
  rename(PU_borough = Borough.x , PU_zone = Zone.x, PU_service_zone = service_zone.x, DO_borough = Borough.y , DO_zone = Zone.y, DO_service_zone = service_zone.y)
head(taxi_data_join)
```

Removed previous dataframes to save GB in Global Environment

```{r}
remove(taxi_data_clean,taxi_zones)
```

Returning Weekday

```{r}
taxi_data_join$weekday = wday(taxi_data_join$lpep_pickup_datetime, label = TRUE, abbr = FALSE)
```

Returning Day of Week

```{r}
taxi_data_join$dow = wday(taxi_data_join$lpep_pickup_datetime, label = FALSE, week_start = getOption("lubridate.week.start", 7))
```

Returning Day of month

```{r}
taxi_data_join$month_day = mday(taxi_data_join$lpep_pickup_datetime)
```

Extracting year from date/time column

```{r}
taxi_data_join$year <- year(taxi_data_join$lpep_pickup_datetime)
```

Extracting month name

```{r}
taxi_data_join$month_name = month(taxi_data_join$lpep_pick, label = TRUE, abbr = FALSE)
```

Extracting date/time

```{r}
taxi_data_join_2 <-taxi_data_join %>% 
  mutate(
    date = as.Date(taxi_data_join$lpep_pickup_datetime),
    hour = hour(taxi_data_join$lpep_pickup_datetime),
    minute = minute(taxi_data_join$lpep_pickup_datetime),
    second = second(taxi_data_join$lpep_pickup_datetime))
```

Removing more columns

```{r}
select(taxi_data_join_2, -minute, -second)
```

Relocating the join result

```{r}
taxi_data_join_3 <- taxi_data_join_2 %>% 
  relocate(PU_borough, PU_zone, PU_service_zone, .before = DOLocationID) %>% 
  relocate(DO_borough, DO_zone, DO_service_zone, .before = passenger_count) %>% 
  relocate(store_and_fwd_flag, .before = passenger_count) %>% 
  relocate(date, .before = PULocationID)
```

This didn't work for some reason to remove columns

```{r}
taxi_data_join_4 <- taxi_data_join_3  
select(taxi_data_join_4, -minute, -second)
```

```{r}
remove(taxi_data_join, taxi_data_join_2, taxi_data_join_3)
```

Removed columns using the below method again.

```{r}
taxi_data_join_4$minute <- NULL
taxi_data_join_4$second <- NULL
```

```{r}
head(taxi_data_join_4)
```

Saving the final clean copy of data to use in separate r markdown. One for cleaning and one for visualizing.

```{r}
fwrite(taxi_data_join_4, "clean_data_haoguo.csv")
```